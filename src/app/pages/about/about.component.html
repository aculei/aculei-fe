<div class="h-full w-full mt-28 font-mono_lite text-gray-200">
  <div class="flex justify-center items-center text-sm">
    <div class="w-1/3 grid grid-cols-1 gap-6 uppercase text-center">
      <div>
        <p class="text-[0.6rem] text-gray-400">PHOTOGRAPHER & DIRECTOR</p>
        <a href="https://tobiafaverio.com" target="_blank">TOBIA FAVERIO</a>
      </div>
      <div class="grid grid-cols-3">
        <div>
          <p class="text-[0.6rem] text-gray-400">FRONTEND DEVELOPMENT</p>
          <a href="https://youssefhanna.it" target="_blank">YOUSSEF HANNA</a>
        </div>
        <div>
          <p class="text-[0.6rem] text-gray-400">AI DEVELOPMENT</p>
          <a href="https://benzebra.github.io" target="_blank"
            >FILIPPO BRAJUCHA</a
          >
        </div>
        <div>
          <p class="text-[0.6rem] text-gray-400">
            BACKEND, AI, INFRASTRUCTURE DEVELOPMENT
          </p>
          <a href="https://micheledinelli.github.io" target="_blank"
            >MICHELE DINELLI</a
          >
        </div>
      </div>
      <div>
        <p class="text-[0.6rem] text-gray-400">ART & WEB DESIGN</p>
        <a
          href="https://www.linkedin.com/in/martina-bracchi-0544491b0/"
          target="_blank"
          >MARTINA BRACCHI</a
        >
      </div>
    </div>
  </div>
  <div class="mt-28 flex justify-center items-center text-sm">
    <div class="w-screen grid grid-cols-4 gap-6 uppercase text-center">
      <div class="justify-self-start">I. INTRODUCTION</div>
      <div class="justify-self-start col-span-3 text-left text-sm/6">
        Computer vision, a pivotal domain within artificial intelligence,
        focuses on enabling machines to interpret and derive meaningful
        information from digital images, videos, and other visual inputs.
        Analogous to the human visual system, which learns to recognize and
        contextualize visual stimuli through years of experience, computer
        vision systems must acquire this capability in a significantly
        compressed timeframe. This is typically achieved through deep learning
        methodologies, with
        <span class="text-green-600">Convolutional Neural Networks</span> (CNNs)
        playing a central role due to their capacity to model spatial
        hierarchies and learn high-level features from raw pixel data. In recent
        years, computer vision has evolved from simple pattern recognition to
        more complex visual reasoning, supported by a rapidly growing ecosystem
        of algorithms and pre-trained models. Among the techniques applied in
        this project are Optical Character Recognition (OCR)—used to extract
        textual information embedded within images—and
        <span class="text-green-600">zero-shot image classification</span>,
        which enables classification of visual content without requiring prior
        task-specific annotated examples. The latter is made possible through
        the use of vision-language models such as CLIP, which align textual and
        visual modalities in a shared embedding space. These methodologies have
        been extensively employed in the construction and processing of the
        Aculei dataset, which comprises over 16,000 automatically captured
        wildlife photographs. Given the scale and unstructured nature of the
        data, traditional manual annotation is infeasible. Thus, leveraging
        computer vision is not merely advantageous but essential for extracting
        semantic insights, identifying species, and organizing the dataset in a
        meaningful and interactive manner. The resulting archive serves both
        scientific and artistic goals, functioning as a computational lens into
        the natural ecosystem of the Umbrian forests while offering a novel mode
        of visual storytelling.
      </div>
      <div class="justify-self-start">II. DESCRIPTION OF THE PROBLEM</div>
      <div class="justify-self-start col-span-3 text-left text-sm/6">
        The Aculei project is a collaborative effort that merges the realms of
        art and science, with the aim of creating an interactive archive of
        wildlife images captured by a network of seven hunter cameras installed
        in the Picco dell'Aquila valley in Umbria, Italy. This initiative is
        driven by a dual purpose: to document the biodiversity of the region
        while also exploring the intersection of technology and nature. The
        project employs advanced computer vision techniques to analyze and
        classify the captured images, enabling a deeper understanding of the
        local ecosystem. By utilizing machine learning algorithms, the archive
        not only serves as a scientific resource but also as an artistic
        expression, inviting viewers to engage with the natural world in a new
        and immersive way. The collaboration between artists and scientists in
        this project exemplifies the potential for interdisciplinary approaches
        to address complex environmental challenges.
      </div>
    </div>
  </div>
</div>
